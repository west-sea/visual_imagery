{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa92ad3-8897-4294-a7a5-34a6944fb147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Setting up band-pass filter from 0.5 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 3301 samples (6.602 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHR\\AppData\\Local\\Temp\\ipykernel_20116\\4091907367.py:21: RuntimeWarning: filter_length (3301) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs_filtered = epochs.copy().filter(l_freq=0.5, h_freq=40.0)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up high-pass filter at 1 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 31 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 15 components\n",
      "Fitting ICA took 1.1s.\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 31 PCA components\n",
      "(60, 31, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHR\\AppData\\Local\\Temp\\ipykernel_20116\\4091907367.py:30: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  data_3d = reconst_raw.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Setting up band-pass filter from 0.5 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 3301 samples (6.602 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHR\\AppData\\Local\\Temp\\ipykernel_20116\\4091907367.py:40: RuntimeWarning: filter_length (3301) is longer than the signal (2000), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  test_epochs_filtered = test_epochs.copy().filter(l_freq=0.5, h_freq=40.0)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up high-pass filter at 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 31 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA took 1.1s.\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 31 PCA components\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHR\\AppData\\Local\\Temp\\ipykernel_20116\\4091907367.py:49: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  test_data_3d = test_reconst_raw.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 40.3871, Accuracy: 0.2500\n",
      "Epoch [2/100], Loss: 27.2968, Accuracy: 0.2000\n",
      "Epoch [3/100], Loss: 19.1039, Accuracy: 0.2833\n",
      "Epoch [4/100], Loss: 21.2251, Accuracy: 0.2000\n",
      "Epoch [5/100], Loss: 16.2231, Accuracy: 0.1500\n",
      "Epoch [6/100], Loss: 7.7877, Accuracy: 0.3333\n",
      "Epoch [7/100], Loss: 5.8888, Accuracy: 0.2333\n",
      "Epoch [8/100], Loss: 8.7652, Accuracy: 0.3167\n",
      "Epoch [9/100], Loss: 9.5841, Accuracy: 0.1667\n",
      "Epoch [10/100], Loss: 11.1542, Accuracy: 0.3167\n",
      "Epoch [11/100], Loss: 9.5350, Accuracy: 0.2000\n",
      "Epoch [12/100], Loss: 5.1195, Accuracy: 0.2333\n",
      "Epoch [13/100], Loss: 8.4004, Accuracy: 0.2333\n",
      "Epoch [14/100], Loss: 7.2591, Accuracy: 0.3333\n",
      "Epoch [15/100], Loss: 12.0809, Accuracy: 0.1833\n",
      "Epoch [16/100], Loss: 11.0835, Accuracy: 0.2667\n",
      "Epoch [17/100], Loss: 11.0149, Accuracy: 0.2500\n",
      "Epoch [18/100], Loss: 6.9594, Accuracy: 0.3000\n",
      "Epoch [19/100], Loss: 9.5273, Accuracy: 0.3167\n",
      "Epoch [20/100], Loss: 6.4874, Accuracy: 0.2500\n",
      "Epoch [21/100], Loss: 8.5439, Accuracy: 0.2833\n",
      "Epoch [22/100], Loss: 7.7651, Accuracy: 0.2500\n",
      "Epoch [23/100], Loss: 6.0377, Accuracy: 0.3333\n",
      "Epoch [24/100], Loss: 9.1391, Accuracy: 0.2000\n",
      "Epoch [25/100], Loss: 5.7404, Accuracy: 0.3500\n",
      "Epoch [26/100], Loss: 4.0683, Accuracy: 0.3333\n",
      "Epoch [27/100], Loss: 3.5564, Accuracy: 0.3333\n",
      "Epoch [28/100], Loss: 3.4017, Accuracy: 0.3667\n",
      "Epoch [29/100], Loss: 4.3947, Accuracy: 0.2333\n",
      "Epoch [30/100], Loss: 3.6968, Accuracy: 0.4167\n",
      "Epoch [31/100], Loss: 8.2496, Accuracy: 0.3667\n",
      "Epoch [32/100], Loss: 11.2200, Accuracy: 0.1667\n",
      "Epoch [33/100], Loss: 8.2309, Accuracy: 0.3167\n",
      "Epoch [34/100], Loss: 4.6044, Accuracy: 0.3000\n",
      "Epoch [35/100], Loss: 5.1237, Accuracy: 0.3333\n",
      "Epoch [36/100], Loss: 4.8476, Accuracy: 0.3667\n",
      "Epoch [37/100], Loss: 3.4298, Accuracy: 0.3333\n",
      "Epoch [38/100], Loss: 2.4590, Accuracy: 0.5167\n",
      "Epoch [39/100], Loss: 2.9960, Accuracy: 0.5000\n",
      "Epoch [40/100], Loss: 2.8319, Accuracy: 0.4500\n",
      "Epoch [41/100], Loss: 5.3755, Accuracy: 0.3667\n",
      "Epoch [42/100], Loss: 3.8016, Accuracy: 0.4000\n",
      "Epoch [43/100], Loss: 3.8280, Accuracy: 0.4333\n",
      "Epoch [44/100], Loss: 3.2336, Accuracy: 0.5000\n",
      "Epoch [45/100], Loss: 2.7031, Accuracy: 0.5000\n",
      "Epoch [46/100], Loss: 4.5772, Accuracy: 0.3500\n",
      "Epoch [47/100], Loss: 3.2152, Accuracy: 0.4500\n",
      "Epoch [48/100], Loss: 3.3813, Accuracy: 0.4500\n",
      "Epoch [49/100], Loss: 5.3824, Accuracy: 0.4667\n",
      "Epoch [50/100], Loss: 2.1259, Accuracy: 0.5167\n",
      "Epoch [51/100], Loss: 2.0136, Accuracy: 0.5833\n",
      "Epoch [52/100], Loss: 1.6495, Accuracy: 0.5167\n",
      "Epoch [53/100], Loss: 1.3634, Accuracy: 0.6167\n",
      "Epoch [54/100], Loss: 1.7195, Accuracy: 0.5667\n",
      "Epoch [55/100], Loss: 1.8544, Accuracy: 0.6333\n",
      "Epoch [56/100], Loss: 1.6312, Accuracy: 0.6333\n",
      "Epoch [57/100], Loss: 1.9934, Accuracy: 0.5000\n",
      "Epoch [58/100], Loss: 1.4944, Accuracy: 0.6333\n",
      "Epoch [59/100], Loss: 1.5632, Accuracy: 0.6667\n",
      "Epoch [60/100], Loss: 1.6956, Accuracy: 0.5667\n",
      "Epoch [61/100], Loss: 1.7414, Accuracy: 0.6333\n",
      "Epoch [62/100], Loss: 2.2793, Accuracy: 0.6000\n",
      "Epoch [63/100], Loss: 2.0078, Accuracy: 0.5333\n",
      "Epoch [64/100], Loss: 2.1520, Accuracy: 0.5500\n",
      "Epoch [65/100], Loss: 1.1179, Accuracy: 0.7167\n",
      "Epoch [66/100], Loss: 1.0518, Accuracy: 0.7667\n",
      "Epoch [67/100], Loss: 0.6559, Accuracy: 0.8000\n",
      "Epoch [68/100], Loss: 1.2314, Accuracy: 0.6667\n",
      "Epoch [69/100], Loss: 2.3874, Accuracy: 0.5333\n",
      "Epoch [70/100], Loss: 1.4957, Accuracy: 0.6500\n",
      "Epoch [71/100], Loss: 1.4663, Accuracy: 0.6167\n",
      "Epoch [72/100], Loss: 0.8292, Accuracy: 0.7000\n",
      "Epoch [73/100], Loss: 2.0953, Accuracy: 0.6167\n",
      "Epoch [74/100], Loss: 1.3925, Accuracy: 0.6833\n",
      "Epoch [75/100], Loss: 2.1356, Accuracy: 0.6333\n",
      "Epoch [76/100], Loss: 1.1900, Accuracy: 0.6333\n",
      "Epoch [77/100], Loss: 1.0238, Accuracy: 0.7167\n",
      "Epoch [78/100], Loss: 0.5582, Accuracy: 0.8000\n",
      "Epoch [79/100], Loss: 0.7253, Accuracy: 0.8000\n",
      "Epoch [80/100], Loss: 0.6518, Accuracy: 0.7000\n",
      "Epoch [81/100], Loss: 1.2762, Accuracy: 0.7000\n",
      "Epoch [82/100], Loss: 0.7158, Accuracy: 0.8000\n",
      "Epoch [83/100], Loss: 1.8711, Accuracy: 0.6667\n",
      "Epoch [84/100], Loss: 2.4008, Accuracy: 0.7000\n",
      "Epoch [85/100], Loss: 0.9602, Accuracy: 0.7500\n",
      "Epoch [86/100], Loss: 2.2455, Accuracy: 0.6000\n",
      "Epoch [87/100], Loss: 1.5303, Accuracy: 0.6667\n",
      "Epoch [88/100], Loss: 1.0971, Accuracy: 0.6833\n",
      "Epoch [89/100], Loss: 0.5727, Accuracy: 0.7833\n",
      "Epoch [90/100], Loss: 0.5715, Accuracy: 0.7667\n",
      "Epoch [91/100], Loss: 0.6422, Accuracy: 0.7833\n",
      "Epoch [92/100], Loss: 0.2889, Accuracy: 0.8833\n",
      "Epoch [93/100], Loss: 0.3428, Accuracy: 0.9000\n",
      "Epoch [94/100], Loss: 0.3883, Accuracy: 0.8500\n",
      "Epoch [95/100], Loss: 0.5696, Accuracy: 0.8500\n",
      "Epoch [96/100], Loss: 0.4667, Accuracy: 0.8500\n",
      "Epoch [97/100], Loss: 0.3633, Accuracy: 0.8667\n",
      "Epoch [98/100], Loss: 0.1854, Accuracy: 0.9333\n",
      "Epoch [99/100], Loss: 0.8671, Accuracy: 0.8167\n",
      "Epoch [100/100], Loss: 1.4773, Accuracy: 0.6500\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import mne\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from epochsMaker import import_EEG, EEG_to_epochs\n",
    "from mne.preprocessing import ICA, corrmap, create_ecg_epochs, create_eog_epochs\n",
    "\n",
    "# EEG 데이터 가져오기 및 전처리\n",
    "file_name = '[CGL]VI_12.txt'\n",
    "eeg_array, label_array = import_EEG(file_name)\n",
    "epochs = EEG_to_epochs(eeg_array, label_array)\n",
    "\n",
    "event_id = {'Rest': 0, 'Right Hand': 1, 'Left Hand': 2, 'Feet': 3}  \n",
    "events = epochs.events\n",
    "event_name_map = {code: name for name, code in event_id.items()}\n",
    "\n",
    "epochs_filtered = epochs.copy().filter(l_freq=0.5, h_freq=40.0)\n",
    "filt_raw = epochs_filtered.copy().filter(l_freq=1.0, h_freq=None)\n",
    "\n",
    "ica = ICA(n_components=15, max_iter=\"auto\", random_state=97)\n",
    "ica.fit(epochs_filtered)\n",
    "ica.exclude = [1]\n",
    "reconst_raw = epochs_filtered.copy()\n",
    "ica.apply(reconst_raw)\n",
    "\n",
    "data_3d = reconst_raw.get_data()  \n",
    "print(data_3d.shape)\n",
    "labels = epochs.events[:, -1]\n",
    "\n",
    "\n",
    "# 테스트 데이터 가져오기 및 전처리\n",
    "test_file_name = '[CGL]VI_11.txt'\n",
    "test_eeg_array, test_label_array = import_EEG(test_file_name)\n",
    "test_epochs = EEG_to_epochs(test_eeg_array, test_label_array)\n",
    "\n",
    "test_epochs_filtered = test_epochs.copy().filter(l_freq=0.5, h_freq=40.0)\n",
    "test_filt_raw = test_epochs_filtered.copy().filter(l_freq=1.0, h_freq=None)\n",
    "\n",
    "test_ica = ICA(n_components=15, max_iter=\"auto\", random_state=97)\n",
    "test_ica.fit(test_epochs_filtered)\n",
    "test_ica.exclude = [1]\n",
    "test_reconst_raw = test_epochs_filtered.copy()\n",
    "test_ica.apply(test_reconst_raw)\n",
    "\n",
    "test_data_3d = test_reconst_raw.get_data()\n",
    "test_labels = test_epochs.events[:, -1]\n",
    "\n",
    "\n",
    "# ShallowConvNet 모델 정의\n",
    "class ShallowConvNet(nn.Module):\n",
    "    def __init__(self, num_channels, output_dim=4, dropout_prob=0.3):\n",
    "        super(ShallowConvNet, self).__init__()\n",
    "\n",
    "        self.conv_temp = nn.Conv2d(1, 40, kernel_size=(1, 25)) \n",
    "        self.conv_spat = nn.Conv2d(40, 40, kernel_size=(num_channels, 1), bias=False) \n",
    "        self.batchnorm1 = nn.BatchNorm2d(40, momentum=0.1, affine=True, eps=1e-5)\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=(1, 75), stride=(1, 15)) \n",
    "        self.dropout1 = nn.Dropout(p=dropout_prob)\n",
    "        self.fc = nn.Linear(self._calc_fc_input_dim(num_channels), output_dim)\n",
    "\n",
    "    def _calc_fc_input_dim(self, num_channels):\n",
    "        x = torch.zeros((1, 1, num_channels, 6000))  # 실제 데이터와 유사한 크기\n",
    "        x = self.conv_temp(x)\n",
    "        x = self.conv_spat(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = torch.square(x)\n",
    "        x = self.avgpool1(x)\n",
    "        #return x.view(1, -1).size(1)  # fc 레이어 입력 크기 \n",
    "        return 5080\n",
    "\n",
    "    def forward(self, input):\n",
    "        if len(input.shape) == 3:\n",
    "            input = input.unsqueeze(1)\n",
    "        \n",
    "        x = self.conv_temp(input)\n",
    "        x = self.conv_spat(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = torch.square(x)\n",
    "        x = self.avgpool1(x)\n",
    "        x = torch.log(torch.clamp(x, min=1e-6))\n",
    "        x = self.dropout1(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        output = self.fc(x)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# 데이터로더 준비\n",
    "def prepare_dataloader(data, labels, batch_size=32):\n",
    "    dataset = TensorDataset(torch.tensor(data, dtype=torch.float32), torch.tensor(labels, dtype=torch.long))\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_model(model, dataloader, num_epochs=40, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "# 실제 학습 시작\n",
    "num_channels = 31\n",
    "output_dim = 4\n",
    "dropout_prob = 0.3\n",
    "batch_size = 8\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "dataloader = prepare_dataloader(data_3d, labels, batch_size=batch_size)\n",
    "test_dataloader = prepare_dataloader(test_data_3d, labels, batch_size=batch_size)\n",
    "model = ShallowConvNet(num_channels, output_dim, dropout_prob)\n",
    "\n",
    "train_model(model, dataloader, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647b5188-a4a1-45ea-8509-a320fa825d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import Accuracy\n",
    "#from getOtherData2 import get_data_2a\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069c4d25-25ab-4187-aa1f-7cb34a7734a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "from collections import deque\n",
    "\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def evaluate(model, test_loader, loss_fn):\n",
    "    model.eval()  # 모델을 평가 모드로 전환\n",
    "    loss_test = AverageMeter()  # 손실을 추적하기 위한 AverageMeter 인스턴스 생성\n",
    "    acc_test = Accuracy(task=\"multiclass\", num_classes=4).to(device)  # 정확도를 계산하기 위한 Accuracy 인스턴스 생성\n",
    "\n",
    "    all_preds = deque()\n",
    "    all_labels = deque()\n",
    "\n",
    "    with torch.no_grad():  # 평가 모드에서는 기울기를 계산하지 않도록 no_grad 블록 사용\n",
    "        for inputs, targets in test_loader:  # 테스트 데이터 로더에서 입력과 타겟 데이터를 가져옴\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # 데이터를 장치(CPU 또는 GPU)로 이동\n",
    "            outputs = model(inputs)  # 모델을 사용하여 예측값 계산\n",
    "            loss = loss_fn(outputs, targets)  # 예측값과 타겟을 사용하여 손실 계산\n",
    "\n",
    "            loss_test.update(loss.item(), inputs.size(0))  # 손실 값을 업데이트\n",
    "            acc_test.update(outputs, targets)  # 정확도 업데이트\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    return loss_test.avg, acc_test.compute().item() #list(all_preds), list(all_labels)  # 평균 손실, 정확도, 예측값 및 실제 라벨 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f57eeb-f3f1-48dd-9ee7-2fe91e7828c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model using E data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m loss_test, acc_test \u001b[38;5;241m=\u001b[39m evaluate(model, test_dataloader, \u001b[43mloss_fn\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE Test Loss after: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_test\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, E Test Accuracy after: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_test\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m loss_test, acc_test \u001b[38;5;241m=\u001b[39m evaluate(model, dataloader, loss_fn)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_fn' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using E data\n",
    "loss_test, acc_test = evaluate(model, test_dataloader, loss_fn)\n",
    "print(f'E Test Loss after: {loss_test:.4f}, E Test Accuracy after: {acc_test:.4f}')\n",
    "loss_test, acc_test = evaluate(model, dataloader, loss_fn)\n",
    "print(f'T Train Loss after: {loss_test:.4f}, T Train Accuracy after: {acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818554b7-4b2a-43a5-b1d7-a394f29964aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744b28c-c958-4028-b420-c35874acde24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
